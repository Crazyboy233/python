```mermaid
flowchart TB
    %% 定义节点样式
    subgraph PS集群[参数服务器集群 PS Cluster]
        direction TB
        PS1[PS Node 1<br/>存储参数分片1]
        PS2[PS Node 2<br/>存储参数分片2]
        PS3[PS Node 3<br/>存储参数分片3]
        PS_Mgr[PS Manager<br/>参数分片管理/同步]
        PS1 --- PS_Mgr
        PS2 --- PS_Mgr
        PS3 --- PS_Mgr
    end

    subgraph Worker集群[计算节点集群 Worker Cluster]
        direction TB
        Worker1[Worker Node 1<br/>计算分片1]
        Worker2[Worker Node 2<br/>计算分片2]
        Worker3[Worker Node 3<br/>计算分片3]
        Worker_Mgr[Worker Manager<br/>任务分配/数据分片]
        Worker1 --- Worker_Mgr
        Worker2 --- Worker_Mgr
        Worker3 --- Worker_Mgr
    end

    subgraph Data[训练数据集]
        Data_Split[数据分片<br/>按Worker数量拆分]
    end

    %% 核心流程（循环迭代直到收敛）
    Start[训练开始<br/>初始化模型参数] --> PS_Mgr
    PS_Mgr -->|初始化参数分片| PS1 & PS2 & PS3
    Data -->|1. 分配数据分片| Data_Split
    Data_Split -->|推送至对应Worker| Worker1 & Worker2 & Worker3

    %% Worker通用流程（以Worker1为例，Worker2/3流程完全一致）
    Worker1 -->|2. Pull：拉取对应参数分片| PS1 & PS2 & PS3
    PS1 & PS2 & PS3 -->|返回当前参数weight| Worker1
    
    Worker1 -->|3. 前向传播 Forward| W1_Forward[计算批次输出y_pred<br/>计算Loss]
    W1_Forward -->|4. 反向传播 Backward| W1_Backward[计算参数梯度grad]
    W1_Backward -->|5. 本地参数更新 Update| W1_Update[weight = weight - lr*grad]
    W1_Update -->|6. Push：推送更新后的参数分片| PS1 & PS2 & PS3
    
    %% Worker2/3 同步流程
    Worker2 -->|2. Pull：拉取参数分片| PS1 & PS2 & PS3
    PS1 & PS2 & PS3 -->|返回参数| Worker2
    Worker2 --> W2_Forward[Forward] --> W2_Backward[Backward] --> W2_Update[Update] -->|6. Push| PS1 & PS2 & PS3
    
    Worker3 -->|2. Pull：拉取参数分片| PS1 & PS2 & PS3
    PS1 & PS2 & PS3 -->|返回参数| Worker3
    Worker3 --> W3_Forward[Forward] --> W3_Backward[Backward] --> W3_Update[Update] -->|6. Push| PS1 & PS2 & PS3

    %% PS集群参数聚合与同步
    PS1 & PS2 & PS3 -->|7. 聚合多Worker更新| PS_Mgr
    PS_Mgr -->|8. 同步参数分片（平均/累加）| PS1 & PS2 & PS3
    PS_Mgr -->|判断Loss是否收敛？| Judge{收敛？}
    Judge -->|否| Worker_Mgr[重新分配数据分片]
    Worker_Mgr --> Worker1 & Worker2 & Worker3
    Judge -->|是| End[训练结束<br/>输出最终模型参数]

    %% 标注核心动作
    note1[核心动作：Pull/Push 实现参数跨节点同步]
    note2[核心动作：Forward/Backward 实现梯度计算]
    note3[核心动作：Update 实现本地参数更新]
    note1 -.-> Worker1
    note2 -.-> W1_Forward
    note3 -.-> W1_Update
```
**整体流程**：计算节点会**pull**参数，然后**ps**返回参数，然后计算节点开始前向计算**loss**，反向计算梯度**grad**，然后**push**，最后 ps 根据梯度和优化器**update**更新参数。

注：
- **数据分片阶段**：按批次动态分片（先获取总批次数据(batch_size * worker)→分片→执行→下一轮再取新批次）
- **计算阶段**：在计算节点 **update** 完向 **ps** 节点 **push** 参数时，是向 **pull** 参数的节点 **push** 而不是所有 **ps** 节点。
- **聚合多 worker 更新**：同一个参数分片可能会被多个 Worker 同时更新。，此时，PS Manager 会让负责该参数分片的 PS 节点，对所有 Worker 推送的同一份参数更新执行聚合运算，生成一个全局最优的更新值。（常见聚合策略：梯度平均，参数加权平均，累加更新）
- **同步参数分片**：按需同步，不是全量复制。同步的参数属于 备份/迁移 副本。常见的两种同步场景：
  - **高可用备份**：防止参数归属的 PS 节点宕机，导致参数丢失。
    1. PS Manager 让 某个 ps 节点 把最新的 参数，同步一份只读备份到 另一个ps节点，备份节点（PS3）不参与正常的 Pull/Push，
    2. 只有当 PS1 宕机时，PS Manager 才会更新映射表，让 Worker 改从 PS3 拉取参数。
  - **负载均衡迁移同步**：解决 PS 节点负载不均（比如 PS1 存储的参数太多，计算压力大）。操作如下：
    1. PS Manager 决定把conv1.weight从 PS1 迁移到 PS2。
    2. PS1 将最新的conv1.weight同步到 PS2
    3. PS Manager 向所有 Worker 推送更新后的映射表（conv1.weight → PS2）
    4. 下一轮训练，Worker 就会改向 PS2 拉取这个参数，PS1 不再负责该参数。